{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#use all the words in a sentence as features directly, regardless of selection\n",
    "def preprocess(s):\n",
    "    return {word: True for word in s.lower().split()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Claim topic classification\n",
    "\n",
    "#datatype covert to process\n",
    "\n",
    "#load data\n",
    "data=pd.read_csv('claim.csv',sep=',',encoding='utf-8',low_memory=False) \n",
    "\n",
    "#panda dataframe convert to list so we can process it later\n",
    "t1 = data[data['topic']=='Religion does more harm than good']\n",
    "t1cont = t1['sentence']\n",
    "list_t1 = t1cont.tolist()\n",
    "\n",
    "t2 = data[data['topic']=='Science is a major threat']\n",
    "t2cont = t2['sentence']\n",
    "list_t2 = t2cont.tolist()\n",
    "\n",
    "t3 = data[data['topic']=='Newspapers are outdated']\n",
    "t3cont = t3['sentence']\n",
    "list_t3 = t3cont.tolist()\n",
    "\n",
    "#features of each class\n",
    "t1feats=[(preprocess(str(list_t1[i])), 't1') for i in range(len(list_t1))]\n",
    "t2feats=[(preprocess(str(list_t2[i])), 't2') for i in range(len(list_t2))]\n",
    "t3feats=[(preprocess(str(list_t3[i])), 't3') for i in range(len(list_t3))]\n",
    "\n",
    "#training and testing ratio \n",
    "t1cutoff = int(len(t1feats)*0.8)\n",
    "t2cutoff = int(len(t2feats)*0.8)\n",
    "t3cutoff = int(len(t3feats)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 300590 instances, test on 75149 instances\n",
      "accuracy: 0.9478502707953532\n",
      "Most Informative Features\n",
      "               religions = True               t1 : t3     =   1207.4 : 1.0\n",
      "              newspaper. = True               t3 : t2     =    978.2 : 1.0\n",
      "             newspaper's = True               t3 : t1     =    883.0 : 1.0\n",
      "                science. = True               t2 : t3     =    717.2 : 1.0\n",
      "               religion. = True               t1 : t3     =    598.5 : 1.0\n",
      "             newspapers. = True               t3 : t1     =    598.4 : 1.0\n",
      "              newspaper, = True               t3 : t2     =    525.8 : 1.0\n",
      "              religions. = True               t1 : t3     =    493.2 : 1.0\n",
      "               religion, = True               t1 : t3     =    492.1 : 1.0\n",
      "              religious, = True               t1 : t3     =    475.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#training set \n",
    "trainfeats = t1feats[:t1cutoff]+t2feats[:t2cutoff]+t3feats[:t3cutoff]\n",
    "#testing set\n",
    "testfeats = t1feats[t1cutoff:]+t2feats[t2cutoff:]+t3feats[t3cutoff:]\n",
    "\n",
    "print ('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))\n",
    "\n",
    "#naive bayesian model\n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other models\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(trainfeats)\n",
    "print(\"MultinomialNB accuracy percent:\",nltk.classify.accuracy(MNB_classifier, testfeats))\n",
    "\n",
    "BNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BNB_classifier.train(trainfeats)\n",
    "print(\"BernoulliNB accuracy percent:\",nltk.classify.accuracy(BNB_classifier, testfeats))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(trainfeats)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testfeats))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(trainfeats)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testfeats))*100)\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(trainfeats)\n",
    "print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testfeats))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(trainfeats)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testfeats))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(trainfeats)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testfeats))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evidence support or not of a topic classification, same idea same process\n",
    "data1=pd.read_csv('evidence.csv',sep=',',encoding='utf-8',low_memory=False) \n",
    "\n",
    "#count1 = data1.groupby('the concept of the topic').candidate.count()\n",
    "#count1.to_csv('count1.csv')\n",
    "\n",
    "t4 = data1[(data1['the concept of the topic']=='cannabis') & (data1['label']==1)]\n",
    "t4cont = t4['candidate']\n",
    "list_t4 = t4cont.tolist()\n",
    "\n",
    "t5 = data1[(data1['the concept of the topic']=='cannabis') & (data1['label']==0)]\n",
    "t5cont = t5['candidate']\n",
    "list_t5 = t5cont.tolist()\n",
    "\n",
    "t6 = data1[(data1['the concept of the topic']=='prostitution') & (data1['label']==0)]\n",
    "t6cont = t6['candidate']\n",
    "list_t6 = t6cont.tolist()\n",
    "\n",
    "t7 = data1[(data1['the concept of the topic']=='prostitution') & (data1['label']==1)]\n",
    "t7cont = t7['candidate']\n",
    "list_t7 = t7cont.tolist()\n",
    "\n",
    "t4feats=[(preprocess(str(list_t4[i])), 't4') for i in range(len(list_t4))]\n",
    "t5feats=[(preprocess(str(list_t5[i])), 't5') for i in range(len(list_t5))]\n",
    "t6feats=[(preprocess(str(list_t6[i])), 't6') for i in range(len(list_t6))]\n",
    "t7feats=[(preprocess(str(list_t7[i])), 't7') for i in range(len(list_t7))]\n",
    "\n",
    "t4cutoff = int(len(t4feats)*0.8)\n",
    "t5cutoff = int(len(t5feats)*0.8)\n",
    "t6cutoff = int(len(t6feats)*0.8)\n",
    "t7cutoff = int(len(t7feats)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 300590 instances, test on 75149 instances\n",
      "accuracy: 0.5588235294117647\n",
      "Most Informative Features\n",
      "                cannabis = None               t7 : t4     =     14.1 : 1.0\n",
      "                   their = True               t6 : t4     =      6.3 : 1.0\n",
      "                      it = True               t6 : t4     =      5.2 : 1.0\n",
      "                     who = True               t7 : t4     =      5.1 : 1.0\n",
      "                    have = True               t5 : t7     =      4.9 : 1.0\n",
      "                 control = True               t5 : t4     =      4.9 : 1.0\n",
      "                     are = True               t6 : t7     =      4.6 : 1.0\n",
      "             prostitutes = True               t6 : t7     =      4.6 : 1.0\n",
      "                   which = True               t7 : t4     =      4.2 : 1.0\n",
      "                  should = True               t7 : t4     =      4.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "trainfeats1 =t4feats[:t4cutoff]+t5feats[:t5cutoff]+t6feats[:t6cutoff]+t7feats[:t7cutoff]\n",
    "testfeats1 = t4feats[t4cutoff:]+t5feats[t5cutoff:]+t6feats[t6cutoff:]+t7feats[t7cutoff:]\n",
    "\n",
    "print ('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(trainfeats1)\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, testfeats1))\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "import nltk.classify\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classifier1 = nltk.classify.SklearnClassifier(LinearSVC())\n",
    "classifier1.train(trainfeats1)\n",
    "\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier1, testfeats1))\n",
    "\n",
    "\n",
    "classifier1.train(trainfeats)\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier1, testfeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0120d230dbba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m '''\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "'''Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "# Notes\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "\n",
    "import keras\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')    \n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=15,validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
